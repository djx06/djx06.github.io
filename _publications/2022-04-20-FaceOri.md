---
title: "FaceOri: Tracking Head Position and Orientation Using Ultrasonic Ranging on Earphones"
collection: publications
permalink: /publication/2022-04-20-faceori
# excerpt: 'This paper is about the number 1. The number 2 is left for future work.'
date: 2022-04-20
venue: 'CHI'
paperurl: 'http://djx06.github.io/files/paper1_faceori.pdf'
citation: 'Yuntao Wang*, Jiexin Ding*, Ishan Chatterjee, Farshid Salemi Parizi, Yuzhou Zhuang, Yukang Yan, Shwetak Patel, and Yuanchun Shi. 2022. FaceOri: Tracking Head Position and Orientation Using Ultrasonic Ranging on Earphones. <i>In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (CHI 22).</i>'
---
<!-- This paper is about the number 1. The number 2 is left for future work. -->

Face orientation can often indicate users’ intended interaction target. In this paper, we propose FaceOri, a novel face tracking technique based on acoustic ranging using earphones. FaceOri can leverage the speaker on a commodity device to emit an ultrasonic chirp, which is picked up by the set of microphones on the user's earphone, and then processed to calculate the distance from each microphone to the device. These measurements are used to derive the user’s face orientation and distance with respect to the device. We conduct a ground truth comparison and user study to evaluate FaceOri's performance. The results show that the system can determine whether the user orients to the device at a 93.5% accuracy within a 1.5 meters range. Furthermore, FaceOri can continuously track user's head orientation with a median absolute error of 10.9 mm in the distance, 3.7$^\circ$ in yaw, and 5.8$^\circ$ in pitch. FaceOri can allow for convenient hands-free control of devices and produce more intelligent context-aware interactions.

My contributions:
* Calculated the real-time distance between the speaker and the microphones embedded in the commodity earbuds using the FMCW acoustic ranging method to detect face orientations. 
* Conducted user study whose result showed that the system can continuously track the user’s head orientation with a median absolute error of 10.9 mm in the distance, 3.7◦ in yaw, and 5.8◦ in pitch. 
* Enabled the binarized attention detection using SVM and reached an accuracy of 93.5%.


[Download paper here](http://djx06.github.io/files/paper1_faceori.pdf)

<!-- Recommended citation: Your Name, You. (2009). "Paper Title Number 1." <i>Journal 1</i>. 1(1). -->